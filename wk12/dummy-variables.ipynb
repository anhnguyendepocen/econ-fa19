{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%;\">\n",
    "    <tr style=\"background-color: transparent;\"><td>\n",
    "        <img src=\"https://d8a-88.github.io/econ-fa19/assets/images/blue_text.png\" width=\"250px\" style=\"margin-left: 0;\" />\n",
    "    </td><td>\n",
    "        <p style=\"text-align: right; font-size: 12pt;\"><strong>Economic Models</strong>, Fall 2019<br>\n",
    "            Dr. Eric Van Dusen</p></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 12 - Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn-muted\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at dummy variables in the context of our project dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = pd.read_csv(\"defaults.csv\")\n",
    "defaults.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why do we need dummary variables?**\n",
    "\n",
    "Two cases:\n",
    "\n",
    "* variable has non-numeric values, e.g. the `sex`, `education`, `marital_status` variables in `defaults`\n",
    "* variable has categorical numeric values, e.g. a Likert scale (1 to $n$ are possible values) or the `age` variable\n",
    "\n",
    "In the first case, the reason is obvious: How can we model a variable that has text as its value?\n",
    "\n",
    "In the second, the reason is more subtle. Let's build two models that model `age`: one with a dummy for `age` and another without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults_age = defaults[[\"age\", \"bill_sep05\"]]\n",
    "\n",
    "def_dummies = pd.get_dummies(defaults, columns=[\"age\"])\n",
    "age_labels = [\"bill_sep05\"] + [l for l in def_dummies.columns if l[:3] == \"age\"]\n",
    "defaults_age_dummies = def_dummies[age_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, Y_1 = defaults_age[[\"age\"]].values, defaults_age[\"bill_sep05\"]\n",
    "X_2, Y_2 = defaults_age_dummies.drop(\"bill_sep05\", axis=1).values, defaults_age_dummies[\"bill_sep05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_1 = sm.OLS(Y_1, X_1).fit().fittedvalues\n",
    "Y_hat_2 = sm.OLS(Y_2, X_2).fit().fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def rmse(y, y_hat):\n",
    "    return np.sqrt(np.mean((y - y_hat)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_1 = rmse(Y_1, Y_hat_1)\n",
    "rmse_2 = rmse(Y_2, Y_hat_2)\n",
    "print(\"RMSE 1: {:.7f}\\nRMSE 2: {:.7f}\".format(rmse_1, rmse_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a drop in the RMSE when we use dummy variables for age because age is not a continuous variable, but a categorical one. With numerical categorical variables, values that are larger in magnitude that others cause greater shifts in model weights due only to their magnitude. This also helps to reveal nonlinear patterns between variables and a categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Get Dummy Variables for a Table\n",
    "\n",
    "You may have noticed that the code above uses the library `pandas`, which you will learn about in Data 100. However, if we want to use the `datascience` library, we need to define our own function to create dummy variables. Let's start by thinking about the intuition of creating dummy variables using a one-column table with only two possible values: `H` or `T`, for the flip of a coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flips = Table().with_column(\"flip\", np.random.choice([\"H\", \"T\"], 200))\n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking about our problem, what's the first thing that we need to know? I propose that we need to know all of the **unique** values of our variable, since we will need to create one new column for each of these. Although we already know our variable has only 2 possible values, \"H\" and \"T\", let's practice anyway. The function `np.unique` will give you an array of the unique values of the array passed to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vals = np.unique(flips.column(\"flip\"))\n",
    "unique_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know these values, we want to create a column for each value with a 1 if the value for that row equals the column value, and a 0 otherwise. To do this, we'll need to use a function that tells us if some value is equal to another pre-specified value. Luckily, you already know these! The predicate functions you use in `Table.where` will do this for us. So let's now look at how we can use these functions to create the columns we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in unique_vals:\n",
    "    dummy_vals = flips.apply(are.equal_to(val), \"flip\")\n",
    "    flips = flips.with_column(\"flip_\" + val, dummy_vals)\n",
    "\n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we've created columns with names of the format `flips_{value}`. However, we still have a problem: these columns have boolean values, not integers!\n",
    "\n",
    "Recall now that we can **typecast** a `bool` to an `int` by calling the `int` function on it. This will map `True` to 1 and `False` to 0. Let's now do this with `Table.apply`. Notice in the cell below that we have added logic to apply this function to _our new columns_ using the format of their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in unique_vals:\n",
    "    int_vals = flips.apply(int, \"flip_\" + val)\n",
    "    flips = flips.with_column(\"flip_\" + val, int_vals)\n",
    "    \n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're almost there! The last thing we want to do is get rid of the original column, so that it doesn't muck up any analysis we do later on. Let's drop it with `Table.drop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flips = flips.drop(\"flip\")\n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you've now created dummy variables for a categorical variable! Notice that our choice to iterate through the unique values means that we can use this same logic for any arbitrarily large number of unique values. The function `get_dummies` defined below encapsulates this logic that we've built, albeit with a simplified encoding step. This function will be provided for you in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(tbl, col, drop=True):\n",
    "    \"\"\"Creates dummy variables for a column of a table\"\"\"\n",
    "    values = np.unique(tbl.column(col))\n",
    "    for val in values:\n",
    "        encoding = tbl.apply(lambda s: int(s == val), col)\n",
    "        tbl = tbl.with_column(col + \"_\" + str(val), encoding)\n",
    "    if drop:\n",
    "        tbl = tbl.drop(col)\n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate this function and its flexibility, let's imagine that we were rolling an icosahedron (a 20-sided die)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolls = Table().with_column(\"roll\", np.random.choice(np.arange(1, 21), 400))\n",
    "rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dummies(rolls, \"roll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
